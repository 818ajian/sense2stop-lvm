{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using puffMarker to check End-of-Day: Exploratory Data Analysis\n",
    "\n",
    "- This notebook is dedicated to understanding End-of-Day EMA using self-report\n",
    "- For every self-report, check to see\n",
    "    + What is the fraction where the user clicked correct hour\n",
    "    + What is the fraction where the user clicked plus/minus one hour\n",
    "- We see that for _aggregated data_, the fraction where EOD agrees with self-report is:\n",
    "    + 0.222 for current hour only\n",
    "    + 0.409 for plus/minus hour\n",
    "- If we assume normal and use midpoint of hour then we can convert to an estimated variance of a normal:\n",
    "    + \\Phi(30/\\sigma) - \\Phi(-30/\\sigma) = 2\\Phi(30/sigma) - 1 = 0.536 -> sigma = 30/ \\Phi^{-1} ( (0.222+1)/2 ) = 106.41 minutes\n",
    "    + \\sigma = 60/ \\Phi^{-1} ( (0.833+1)/2 ) = 111.65 minutes \n",
    "        * Here we use 60 since it was pm one hour so 90 seemed excessive\n",
    "    + We think this suggests that puffMarker isn't reliable (false positives!). \n",
    "    + Will confirm in pM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import os\n",
    "os.getcwd()\n",
    "dir = \"../final-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['8to9', '9to10', '10to11', '11to12','12to13','13to14','14to15','15to16','16to17','17to18','18to19','19to20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "htmgs =  pd.read_csv(os.path.join(os.path.realpath(dir), 'puff-episode-final.csv'))\n",
    "eod_ema = pd.read_csv(os.path.join(os.path.realpath(dir), 'eod-ema-final.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all contingent event-times between 8AM and 8PM\n",
    "# Throw away observations for 'when_smoke' is nan or \n",
    "# 'More than 30 minutes' to ensure we can calculate a meaningful \n",
    "# quantity.\n",
    "days_smoked = {}\n",
    "for index, row in htmgs.iterrows():\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(row['date'], '%m/%d/%y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "    date = (time.year, time.month, time.day, time.hour)\n",
    "    if row['participant_id'] not in days_smoked:\n",
    "        days_smoked[row['participant_id']] = set()\n",
    "    if 8 <= date[3] < 20:        \n",
    "        days_smoked[row['participant_id']].add(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a list of id + dates for eod\n",
    "# Use to look \n",
    "eod_dates = []\n",
    "for irow in range(0,eod_ema.shape[0]):\n",
    "    row = eod_ema.iloc[irow]\n",
    "    if row['status'] == \"MISSED\":\n",
    "        continue\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(row['date'], '%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "    if time.hour  == 0 or time.hour == 1:\n",
    "        date = np.array([row['participant_id'], time.year, time.month, time.day-1])\n",
    "        date = np.append(date, np.array(row[keys]))\n",
    "    else:\n",
    "        date = np.array([row['participant_id'], time.year, time.month, time.day])\n",
    "        date = np.append(date, np.array(row[keys]))\n",
    "    eod_dates.append(date)\n",
    "    \n",
    "eod_dates = np.asarray(eod_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current hour only:\n",
      "Aggregated data, Fraction agreement between EC and EOD: 0.222\n",
      "Mean of Fraction agreement across indidivuals: 0.248\n",
      "Standard deviation of Fraction agreement across indidivuals: 0.206\n",
      "\n",
      "Plus-minus one hour:\n",
      "Aggregated data, Fraction agreement between EC and EOD: 0.409\n",
      "Mean of Fraction agreement across indidivuals: 0.457\n",
      "Standard deviation of Fraction agreement across indidivuals: 0.298\n"
     ]
    }
   ],
   "source": [
    "# For participants with both EC and EOD measurements,\n",
    "# on days when you give both, we ask whether they agree,\n",
    "# up to the current hour, or +- 1 hour in either direction.\n",
    "# The +-1 is max/min by 8AM and 8PM respectively.\n",
    "matching_counts = []\n",
    "max_iloc = 15; min_iloc = 4\n",
    "for id in set(days_smoked.keys()) & set(eod_dates[:,0]):\n",
    "    eod_dates_id = np.where(eod_dates[:,0] == id) \n",
    "    eod_dates_subset = eod_dates[eod_dates_id[0],:]\n",
    "    total_count_id = 0\n",
    "    hour_count_id_true = 0\n",
    "    twohour_count_id_true = 0\n",
    "    for ec_time in days_smoked[id]:\n",
    "        row_iloc = np.where((eod_dates_subset[:,1:4] == ec_time[0:3]).all(axis=1))[0]\n",
    "        if not row_iloc.size > 0:\n",
    "            continue\n",
    "        total_count_id+=1\n",
    "        row = eod_dates_subset[row_iloc][0]\n",
    "        ec_iloc = range(8,20).index(ec_time[3])+4\n",
    "        if row[ec_iloc]==1:\n",
    "            hour_count_id_true+=1\n",
    "        if any(row[range(max(min_iloc, ec_iloc-1), min(max_iloc, ec_iloc+1)+1)] == 1):\n",
    "            twohour_count_id_true+=1\n",
    "    if total_count_id > 0:\n",
    "        matching_counts.append(np.array([total_count_id, hour_count_id_true, twohour_count_id_true], dtype='f'))\n",
    "\n",
    "matching_counts = np.asarray(matching_counts)\n",
    "\n",
    "# matching_counts = np.delete(matching_counts, (np.where(matching_counts[:,0] == 0)[0]), axis=0)\n",
    "\n",
    "# print matching_counts\n",
    "\n",
    "fraction_per_id_onehour = np.divide(matching_counts[:,1],matching_counts[:,0])\n",
    "fraction_per_id_twohour = np.divide(matching_counts[:,2],matching_counts[:,0])\n",
    "\n",
    "aggregate_matching_counts = np.sum(matching_counts, axis=0)\n",
    "\n",
    "aggregate_frac_onehour = aggregate_matching_counts[1]/aggregate_matching_counts[0]\n",
    "aggregate_frac_twohour = aggregate_matching_counts[2]/aggregate_matching_counts[0]\n",
    "\n",
    "print 'Current hour only:'\n",
    "print 'Aggregated data, Fraction agreement between EC and EOD: %s' % (np.round(aggregate_frac_onehour,3))\n",
    "print 'Mean of Fraction agreement across indidivuals: %s' % (np.round(np.mean(fraction_per_id_onehour),3))\n",
    "print 'Standard deviation of Fraction agreement across indidivuals: %s' %  (np.round(np.std(fraction_per_id_onehour),3))\n",
    "print\n",
    "print 'Plus-minus one hour:'\n",
    "print 'Aggregated data, Fraction agreement between EC and EOD: %s' % (np.round(aggregate_frac_twohour,3))\n",
    "print 'Mean of Fraction agreement across indidivuals: %s' % (np.round(np.mean(fraction_per_id_twohour),3))\n",
    "print 'Standard deviation of Fraction agreement across indidivuals: %s' %  (np.round(np.std(fraction_per_id_twohour),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA p-value for current hour: 0.0\n",
      "ANOVA p-value for plus-minus one hour: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute an anova decomposition using the bernoulli likelihood\n",
    "# This will test if there are significant differences across\n",
    "# individuals.\n",
    "\n",
    "llik_onehour = 0; llik_twohour = 0\n",
    "for i in range(0, fraction_per_id_onehour.size):\n",
    "    num_ones_onehour = matching_counts[i,1]\n",
    "    num_zeros_onehour = matching_counts[i,0] - matching_counts[i,1]\n",
    "    if num_ones_onehour > 0.0:\n",
    "        llik_onehour += np.multiply(num_ones_onehour, np.log(fraction_per_id_onehour[i]))\n",
    "    if num_zeros_onehour > 0.0:\n",
    "        llik_onehour += np.multiply(num_zeros_onehour, np.log(1-fraction_per_id_onehour[i]))\n",
    "    num_ones_twohour = matching_counts[i,2]\n",
    "    num_zeros_twohour = matching_counts[i,0] - matching_counts[i,2]\n",
    "    if num_ones_twohour > 0.0:\n",
    "        llik_twohour += np.multiply(num_ones_twohour, np.log(fraction_per_id_twohour[i]))\n",
    "    if num_zeros_twohour > 0.0:\n",
    "        llik_twohour += np.multiply(num_zeros_twohour, np.log(1-fraction_per_id_twohour[i]))\n",
    "\n",
    "agg_num_ones = aggregate_matching_counts[1]\n",
    "agg_num_zeros = aggregate_matching_counts[0] - aggregate_matching_counts[1]\n",
    "agg_llik_onehour = agg_num_ones*np.log(aggregate_frac_onehour)+agg_num_zeros*np.log(1-aggregate_frac_onehour)\n",
    "\n",
    "D_onehour = -2*agg_llik_onehour + 2*llik_onehour\n",
    "\n",
    "agg_num_ones_twohour = aggregate_matching_counts[2]\n",
    "agg_num_zeros_twohour = aggregate_matching_counts[0] - aggregate_matching_counts[2]\n",
    "agg_llik_twohour = agg_num_ones_twohour*np.log(aggregate_frac_twohour)+agg_num_zeros_twohour*np.log(1-aggregate_frac_twohour)\n",
    "\n",
    "D_twohour = -2*agg_llik_twohour + 2*llik_twohour\n",
    "\n",
    "from scipy.stats import chi2\n",
    "n = aggregate_matching_counts[0]\n",
    "k = matching_counts.shape[0]\n",
    "df = k-1\n",
    "\n",
    "print 'ANOVA p-value for current hour: %s' % (1-chi2.cdf(D_onehour, df))\n",
    "print 'ANOVA p-value for plus-minus one hour: %s' % (1-chi2.cdf(D_twohour, df))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
