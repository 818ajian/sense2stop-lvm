{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random EMA and HTMGs: Exploratory Data Analysis\n",
    "\n",
    "- This notebook is dedicated to understanding the number of \n",
    "- Computes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/final'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import packages and set directory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.getcwd()\n",
    "dir = \"/home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/final/\"\n",
    "os.chdir(dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_accptresponse = ['1 - 19 Minutes', '20 - 39 Minutes', '40 - 59 Minutes', \n",
    "                    '60 - 79 Minutes', '80 - 100 Minutes']\n",
    "random_dictionary = {'1 - 19 Minutes': 10, \n",
    "                     '20 - 39 Minutes': 30, \n",
    "                     '40 - 59 Minutes':50,\n",
    "                     '60 - 79 Minutes':70, \n",
    "                     '80 - 100 Minutes':90 } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in relevant data streams\n",
    "random_ema = pd.read_csv(dir + 'random-ema-final.csv')\n",
    "htmgs = pd.read_csv(dir + 'puff-probability-final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] File /home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/finalrandom-ema.csv does not exist: '/home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/finalrandom-ema.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-77e6675283a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom_original_cloud_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m203\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m206\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m221\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m226\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m229\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'random-ema.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrandom_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrandom_ema_alternative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'random-ema-alternative.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wdempsey/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wdempsey/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wdempsey/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wdempsey/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wdempsey/.local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] File /home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/finalrandom-ema.csv does not exist: '/home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/finalrandom-ema.csv'"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "random_original_cloud_ids = [201, 203, 206, 210, 221, 226, 229] \n",
    "random_ema = pd.read_csv(dir + 'random-ema.csv')\n",
    "random_ema = random_ema.drop(['offset'], axis = 1)\n",
    "random_ema_alternative = pd.read_csv(dir + 'random-ema-alternative.csv')\n",
    "random_ema_backup = pd.read_csv(dir + 'random-ema-backup.csv')\n",
    "\n",
    "temp_random_original = random_ema[random_ema['participant_id'].isin(random_original_cloud_ids)]\n",
    "temp_random_alt = random_ema_alternative[~random_ema_alternative['participant_id'].isin(random_original_cloud_ids)]\n",
    "\n",
    "random_complete = pd.concat([temp_random_original, temp_random_alt, random_ema_backup])\n",
    "\n",
    "puffmarker_original_cloud_ids = [201, 203, 206, 210, 221, 229] \n",
    "puffmarker = pd.read_csv(dir + 'puff-probability.csv')\n",
    "puffmarker = puffmarker.drop(['offset'], axis = 1)\n",
    "puffmarker_alternative = pd.read_csv('puff-probability-alternative.csv')\n",
    "puffmarker_backup = pd.read_csv('puff-probability-backup.csv')\n",
    "\n",
    "temp_puffmarker_original = puffmarker[puffmarker['participant_id'].isin(puffmarker_original_cloud_ids)]\n",
    "temp_puffmarker_alt = puffmarker_alternative[~puffmarker_alternative['participant_id'].isin(puffmarker_original_cloud_ids)]\n",
    "\n",
    "puffmarker_complete = pd.concat([temp_puffmarker_original, temp_puffmarker_alt, puffmarker_backup])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_puff(delta):\n",
    "    '''\n",
    "    checks how sensitive is puffmarker coverage of \n",
    "    random EMAs to time window\n",
    "    '''\n",
    "    # print(\"Set delta to {} minutes\".format(delta))\n",
    "\n",
    "    htm_complete_yes = []\n",
    "    htm_complete_no = []\n",
    "    for id in set(contingent_complete['participant_id']) & set(puffmarker_complete['participant_id']):\n",
    "\n",
    "        puffmarker_id = np.where(puffmarker_complete['participant_id'] == id) \n",
    "        puffmarker_subset = puffmarker_complete.iloc[puffmarker_id[0]]\n",
    "        try:\n",
    "            puffmarker_dates_list = [datetime.datetime.strptime(date, '%m/%d/%y %H:%M') for date in puffmarker_subset['date']]\n",
    "        except:\n",
    "            puffmarker_dates_list = [datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in puffmarker_subset['date']]\n",
    "\n",
    "        random_id = np.where(random_complete['participant_id'] == id) \n",
    "        random_subset = random_complete.iloc[random_id[0]]\n",
    "\n",
    "        htm_id_list_yes = []\n",
    "        htm_id_list_no = []\n",
    "        for index, row in random_subset.iterrows():\n",
    "            try:\n",
    "                random_time = datetime.datetime.strptime(row['date'], '%m/%d/%y %H:%M')\n",
    "            except:\n",
    "                random_time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "            if row['when_smoke'] in random_accptresponse:\n",
    "                random_time = random_time - datetime.timedelta(minutes=random_dictionary[row['when_smoke']])\n",
    "            if row['when_smoke'] in random_accptresponse: \n",
    "                htm_count = 0\n",
    "                for index_puff in range(0,len(puffmarker_dates_list)):\n",
    "                    temp = abs((puffmarker_dates_list[index_puff] - random_time).total_seconds() / 60.0)\n",
    "                    if temp <= delta:\n",
    "                        htm_count += 1\n",
    "                htm_id_list_yes.append(htm_count)  \n",
    "            if row['smoke'] == 'No':\n",
    "                htm_count = 0\n",
    "                for index_puff in range(0,len(puffmarker_dates_list)):\n",
    "                    temp = abs((puffmarker_dates_list[index_puff] - random_time).total_seconds() / 60.0)\n",
    "                    if temp <= delta:\n",
    "                        htm_count += 1\n",
    "                htm_id_list_no.append(htm_count)  \n",
    "\n",
    "        htm_complete_yes.append(np.array(htm_id_list_yes, dtype = 'f'))\n",
    "        htm_complete_no.append(np.array(htm_id_list_no, dtype = 'f'))\n",
    "\n",
    "    return htm_complete_yes, htm_complete_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_output(delta):\n",
    "    output_delta_yes, output_delta_no = random_puff(delta)\n",
    "    agg_sum_delta_no = np.asarray([np.sum(arr) for arr in output_delta_no])\n",
    "    agg_mean_delta_no  = np.asarray([np.mean(arr) for arr in output_delta_no])\n",
    "    agg_mean_delta_no  = agg_mean_delta_no[~np.isnan(agg_mean_delta_no)]\n",
    "    agg_count_delta_no  = np.asarray([len(arr) for arr in output_delta_no])\n",
    "    agg_zero_delta_no  = np.asarray([np.count_nonzero(arr==0) for arr in output_delta_no], dtype='f')\n",
    "    ind_zero_delta_no = np.divide(agg_zero_delta_no, agg_count_delta_no)\n",
    "    ind_zero_delta_no = ind_zero_delta_no[~np.isnan(ind_zero_delta_no)]\n",
    "\n",
    "    aggregate_frac_delta_no = np.divide(np.sum(agg_sum_delta_no),np.sum(agg_count_delta_no))\n",
    "    aggregate_fraczero_delta_no = np.divide(np.sum(agg_zero_delta_no),np.sum(agg_count_delta_no))\n",
    "\n",
    "    agg_sum_delta_yes = np.asarray([np.sum(arr) for arr in output_delta_yes])\n",
    "    agg_mean_delta_yes  = np.asarray([np.mean(arr) for arr in output_delta_yes])\n",
    "    agg_mean_delta_yes = agg_mean_delta_yes[~np.isnan(agg_mean_delta_yes)]\n",
    "    agg_count_delta_yes  = np.asarray([len(arr) for arr in output_delta_yes])\n",
    "    agg_zero_delta_yes  = np.asarray([np.count_nonzero(arr==0) for arr in output_delta_yes], dtype='f')\n",
    "    ind_zero_delta_yes = np.divide(agg_zero_delta_yes, agg_count_delta_yes)\n",
    "    ind_zero_delta_yes = ind_zero_delta_yes[~np.isnan(ind_zero_delta_yes)]\n",
    "\n",
    "    aggregate_frac_delta_yes = np.divide(np.sum(agg_sum_delta_yes),np.sum(agg_count_delta_yes))\n",
    "    aggregate_fraczero_delta_yes = np.divide(np.sum(agg_zero_delta_yes),np.sum(agg_count_delta_yes))\n",
    "\n",
    "    print '% s minute window:' % (delta)\n",
    "    print 'Prior to EMA Response: No'\n",
    "    print 'Mean number of HTMGs prior (aggregated data): %s' % (np.round(aggregate_frac_delta_no,3))\n",
    "    print 'Avg number of HTMGs (avg of means across indidivuals): %s' % (np.round(np.mean(agg_mean_delta_no),3))\n",
    "    print 'Std dev of number of HTMGs (of means across indidivuals): %s' %  (np.round(np.std(agg_mean_delta_no),3))\n",
    "    print 'Fraction of time no HTMGs in window (aggregated data): %s' %  (np.round(np.sum(aggregate_fraczero_delta_no),3))\n",
    "    print 'Avg fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.mean(ind_zero_delta_no),3))\n",
    "    print 'Std dev of fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.std(ind_zero_delta_no),3))\n",
    "    print\n",
    "    '''\n",
    "    print '% s minute window:' % (delta)\n",
    "    print 'Prior to EMA Response: Yes'\n",
    "    print 'Mean number of HTMGs prior (aggregated data): %s' % (np.round(aggregate_frac_delta_yes,3))\n",
    "    print 'Avg number of HTMGs (avg of means across indidivuals): %s' % (np.round(np.mean(agg_mean_delta_yes),3))\n",
    "    print 'Std dev of number of HTMGs (of means across indidivuals): %s' %  (np.round(np.std(agg_mean_delta_yes),3))\n",
    "    print 'Fraction of time no HTMGs in window (aggregated data): %s' %  (np.round(np.sum(aggregate_fraczero_delta_yes),3))\n",
    "    print 'Avg fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.mean(ind_zero_delta_yes),3))\n",
    "    print 'Std dev of fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.std(ind_zero_delta_yes),3))\n",
    "    print\n",
    "    '''\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  \n",
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 0.688\n",
      "Avg number of HTMGs (avg of means across indidivuals): 0.665\n",
      "Std dev of number of HTMGs (of means across indidivuals): 0.578\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.626\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.656\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.204\n",
      "\n",
      "15 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 2.124\n",
      "Avg number of HTMGs (avg of means across indidivuals): 1.946\n",
      "Std dev of number of HTMGs (of means across indidivuals): 1.273\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.343\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.369\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.195\n",
      "\n",
      "30 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 4.188\n",
      "Avg number of HTMGs (avg of means across indidivuals): 3.832\n",
      "Std dev of number of HTMGs (of means across indidivuals): 2.183\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.217\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.253\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.191\n",
      "\n",
      "60 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 8.134\n",
      "Avg number of HTMGs (avg of means across indidivuals): 7.556\n",
      "Std dev of number of HTMGs (of means across indidivuals): 4.309\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.136\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.189\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.198\n",
      "\n",
      "90 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 11.93\n",
      "Avg number of HTMGs (avg of means across indidivuals): 10.997\n",
      "Std dev of number of HTMGs (of means across indidivuals): 6.169\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.087\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.114\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.148\n",
      "\n",
      "120 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 15.502\n",
      "Avg number of HTMGs (avg of means across indidivuals): 14.114\n",
      "Std dev of number of HTMGs (of means across indidivuals): 8.145\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.068\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.103\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculate the HTMG coverage for 5, 15, 30, and 60 minutes\n",
    "around the event time.\n",
    "'''\n",
    "\n",
    "summary_output(5)\n",
    "\n",
    "summary_output(15)\n",
    "\n",
    "summary_output(30)\n",
    "\n",
    "summary_output(60)\n",
    "\n",
    "summary_output(90)\n",
    "\n",
    "summary_output(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483.30132246017456\n",
      "31\n",
      "ANOVA p-value for current hour: 0.0\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Compute an anova decomposition using the poisson likelihood\n",
    "This will test if there are significant differences across\n",
    "individuals.\n",
    "'''\n",
    "\n",
    "llik_delta = 0; agg_llik_delta = 0\n",
    "output_delta = contingent_puff(delta)\n",
    "output_delta = np.asarray(output_delta)\n",
    "agg_sum_delta = np.asarray([np.sum(arr) for arr in output_delta])\n",
    "agg_mean_delta  = np.asarray([np.mean(arr) for arr in output_delta])\n",
    "agg_count_delta  = np.asarray([len(arr) for arr in output_delta])\n",
    "aggregate_frac_delta  = np.divide(np.sum(agg_sum_delta),np.sum(agg_count_delta))\n",
    "\n",
    "for i in range(0, agg_mean_delta.size):\n",
    "    user_mean = agg_mean_delta[i]\n",
    "    row = output_delta[i]\n",
    "    if user_mean > 0.0:\n",
    "        llik_delta += np.sum(np.subtract(np.multiply(row, np.log(user_mean)),user_mean))\n",
    "        agg_llik_delta += np.sum(np.subtract(np.multiply(row, np.log(aggregate_frac_delta)),aggregate_frac_delta))\n",
    "\n",
    "D_delta = -2*agg_llik_delta + 2*llik_delta\n",
    "print D_delta\n",
    "\n",
    "\n",
    "from scipy.stats import chi2\n",
    "n = np.sum(agg_count_delta)\n",
    "k = output_delta.shape[0]\n",
    "df = k-1\n",
    "print k\n",
    "\n",
    "print 'ANOVA p-value for current hour: %s' % (1-chi2.cdf(D_delta, df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
