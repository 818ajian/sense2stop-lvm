{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/walterdempsey/Box/MD2K Processed Data/smoking-lvm-cleaned-data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.getcwd()\n",
    "dir = \"/Users/walterdempsey/Box/MD2K Processed Data/smoking-lvm-cleaned-data/\"\n",
    "os.chdir(dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_accptresponse = ['1 - 19 Minutes', '20 - 39 Minutes', '40 - 59 Minutes', \n",
    "                    '60 - 79 Minutes', '80 - 100 Minutes']\n",
    "random_dictionary = {'1 - 19 Minutes': 10, \n",
    "                     '20 - 39 Minutes': 30, \n",
    "                     '40 - 59 Minutes':50,\n",
    "                     '60 - 79 Minutes':70, \n",
    "                     '80 - 100 Minutes':90 } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "random_original_cloud_ids = [201, 203, 206, 210, 221, 226, 229] \n",
    "random_ema = pd.read_csv(dir + 'random-ema.csv')\n",
    "random_ema = random_ema.drop(['offset'], axis = 1)\n",
    "random_ema_alternative = pd.read_csv(dir + 'random-ema-alternative.csv')\n",
    "random_ema_backup = pd.read_csv(dir + 'random-ema-backup.csv')\n",
    "\n",
    "temp_random_original = random_ema[random_ema['participant_id'].isin(random_original_cloud_ids)]\n",
    "temp_random_alt = random_ema_alternative[~random_ema_alternative['participant_id'].isin(random_original_cloud_ids)]\n",
    "\n",
    "random_complete = pd.concat([temp_random_original, temp_random_alt, random_ema_backup])\n",
    "\n",
    "puffmarker_original_cloud_ids = [201, 203, 206, 210, 221, 229] \n",
    "puffmarker = pd.read_csv(dir + 'puff-probability.csv')\n",
    "puffmarker = puffmarker.drop(['offset'], axis = 1)\n",
    "puffmarker_alternative = pd.read_csv('puff-probability-alternative.csv')\n",
    "puffmarker_backup = pd.read_csv('puff-probability-backup.csv')\n",
    "\n",
    "temp_puffmarker_original = puffmarker[puffmarker['participant_id'].isin(puffmarker_original_cloud_ids)]\n",
    "temp_puffmarker_alt = puffmarker_alternative[~puffmarker_alternative['participant_id'].isin(puffmarker_original_cloud_ids)]\n",
    "\n",
    "puffmarker_complete = pd.concat([temp_puffmarker_original, temp_puffmarker_alt, puffmarker_backup])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_puff(delta):\n",
    "    '''\n",
    "    checks how sensitive is puffmarker coverage of \n",
    "    random EMAs to time window\n",
    "    '''\n",
    "    # print(\"Set delta to {} minutes\".format(delta))\n",
    "\n",
    "    htm_complete_yes = []\n",
    "    htm_complete_no = []\n",
    "    for id in set(contingent_complete['participant_id']) & set(puffmarker_complete['participant_id']):\n",
    "\n",
    "        puffmarker_id = np.where(puffmarker_complete['participant_id'] == id) \n",
    "        puffmarker_subset = puffmarker_complete.iloc[puffmarker_id[0]]\n",
    "        try:\n",
    "            puffmarker_dates_list = [datetime.datetime.strptime(date, '%m/%d/%y %H:%M') for date in puffmarker_subset['date']]\n",
    "        except:\n",
    "            puffmarker_dates_list = [datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in puffmarker_subset['date']]\n",
    "\n",
    "        random_id = np.where(random_complete['participant_id'] == id) \n",
    "        random_subset = random_complete.iloc[random_id[0]]\n",
    "\n",
    "        htm_id_list_yes = []\n",
    "        htm_id_list_no = []\n",
    "        for index, row in random_subset.iterrows():\n",
    "            try:\n",
    "                random_time = datetime.datetime.strptime(row['date'], '%m/%d/%y %H:%M')\n",
    "            except:\n",
    "                random_time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "            if row['when_smoke'] in random_accptresponse:\n",
    "                random_time = random_time - datetime.timedelta(minutes=random_dictionary[row['when_smoke']])\n",
    "            if row['when_smoke'] in random_accptresponse: \n",
    "                htm_count = 0\n",
    "                for index_puff in range(0,len(puffmarker_dates_list)):\n",
    "                    temp = abs((puffmarker_dates_list[index_puff] - random_time).total_seconds() / 60.0)\n",
    "                    if temp <= delta:\n",
    "                        htm_count += 1\n",
    "                htm_id_list_yes.append(htm_count)  \n",
    "            if row['smoke'] == 'No':\n",
    "                htm_count = 0\n",
    "                for index_puff in range(0,len(puffmarker_dates_list)):\n",
    "                    temp = abs((puffmarker_dates_list[index_puff] - random_time).total_seconds() / 60.0)\n",
    "                    if temp <= delta:\n",
    "                        htm_count += 1\n",
    "                htm_id_list_no.append(htm_count)  \n",
    "\n",
    "        htm_complete_yes.append(np.array(htm_id_list_yes, dtype = 'f'))\n",
    "        htm_complete_no.append(np.array(htm_id_list_no, dtype = 'f'))\n",
    "\n",
    "    return htm_complete_yes, htm_complete_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_output(delta):\n",
    "    output_delta_yes, output_delta_no = random_puff(delta)\n",
    "    agg_sum_delta_no = np.asarray([np.sum(arr) for arr in output_delta_no])\n",
    "    agg_mean_delta_no  = np.asarray([np.mean(arr) for arr in output_delta_no])\n",
    "    agg_mean_delta_no  = agg_mean_delta_no[~np.isnan(agg_mean_delta_no)]\n",
    "    agg_count_delta_no  = np.asarray([len(arr) for arr in output_delta_no])\n",
    "    agg_zero_delta_no  = np.asarray([np.count_nonzero(arr==0) for arr in output_delta_no], dtype='f')\n",
    "    ind_zero_delta_no = np.divide(agg_zero_delta_no, agg_count_delta_no)\n",
    "    ind_zero_delta_no = ind_zero_delta_no[~np.isnan(ind_zero_delta_no)]\n",
    "\n",
    "    aggregate_frac_delta_no = np.divide(np.sum(agg_sum_delta_no),np.sum(agg_count_delta_no))\n",
    "    aggregate_fraczero_delta_no = np.divide(np.sum(agg_zero_delta_no),np.sum(agg_count_delta_no))\n",
    "\n",
    "    agg_sum_delta_yes = np.asarray([np.sum(arr) for arr in output_delta_yes])\n",
    "    agg_mean_delta_yes  = np.asarray([np.mean(arr) for arr in output_delta_yes])\n",
    "    agg_mean_delta_yes = agg_mean_delta_yes[~np.isnan(agg_mean_delta_yes)]\n",
    "    agg_count_delta_yes  = np.asarray([len(arr) for arr in output_delta_yes])\n",
    "    agg_zero_delta_yes  = np.asarray([np.count_nonzero(arr==0) for arr in output_delta_yes], dtype='f')\n",
    "    ind_zero_delta_yes = np.divide(agg_zero_delta_yes, agg_count_delta_yes)\n",
    "    ind_zero_delta_yes = ind_zero_delta_yes[~np.isnan(ind_zero_delta_yes)]\n",
    "\n",
    "    aggregate_frac_delta_yes = np.divide(np.sum(agg_sum_delta_yes),np.sum(agg_count_delta_yes))\n",
    "    aggregate_fraczero_delta_yes = np.divide(np.sum(agg_zero_delta_yes),np.sum(agg_count_delta_yes))\n",
    "\n",
    "    print '% s minute window:' % (delta)\n",
    "    print 'Prior to EMA Response: No'\n",
    "    print 'Mean number of HTMGs prior (aggregated data): %s' % (np.round(aggregate_frac_delta_no,3))\n",
    "    print 'Avg number of HTMGs (avg of means across indidivuals): %s' % (np.round(np.mean(agg_mean_delta_no),3))\n",
    "    print 'Std dev of number of HTMGs (of means across indidivuals): %s' %  (np.round(np.std(agg_mean_delta_no),3))\n",
    "    print 'Fraction of time no HTMGs in window (aggregated data): %s' %  (np.round(np.sum(aggregate_fraczero_delta_no),3))\n",
    "    print 'Avg fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.mean(ind_zero_delta_no),3))\n",
    "    print 'Std dev of fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.std(ind_zero_delta_no),3))\n",
    "    print\n",
    "    '''\n",
    "    print '% s minute window:' % (delta)\n",
    "    print 'Prior to EMA Response: Yes'\n",
    "    print 'Mean number of HTMGs prior (aggregated data): %s' % (np.round(aggregate_frac_delta_yes,3))\n",
    "    print 'Avg number of HTMGs (avg of means across indidivuals): %s' % (np.round(np.mean(agg_mean_delta_yes),3))\n",
    "    print 'Std dev of number of HTMGs (of means across indidivuals): %s' %  (np.round(np.std(agg_mean_delta_yes),3))\n",
    "    print 'Fraction of time no HTMGs in window (aggregated data): %s' %  (np.round(np.sum(aggregate_fraczero_delta_yes),3))\n",
    "    print 'Avg fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.mean(ind_zero_delta_yes),3))\n",
    "    print 'Std dev of fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.std(ind_zero_delta_yes),3))\n",
    "    print\n",
    "    '''\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  \n",
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 0.688\n",
      "Avg number of HTMGs (avg of means across indidivuals): 0.665\n",
      "Std dev of number of HTMGs (of means across indidivuals): 0.578\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.626\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.656\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.204\n",
      "\n",
      "15 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 2.124\n",
      "Avg number of HTMGs (avg of means across indidivuals): 1.946\n",
      "Std dev of number of HTMGs (of means across indidivuals): 1.273\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.343\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.369\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.195\n",
      "\n",
      "30 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 4.188\n",
      "Avg number of HTMGs (avg of means across indidivuals): 3.832\n",
      "Std dev of number of HTMGs (of means across indidivuals): 2.183\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.217\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.253\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.191\n",
      "\n",
      "60 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 8.134\n",
      "Avg number of HTMGs (avg of means across indidivuals): 7.556\n",
      "Std dev of number of HTMGs (of means across indidivuals): 4.309\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.136\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.189\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.198\n",
      "\n",
      "90 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 11.93\n",
      "Avg number of HTMGs (avg of means across indidivuals): 10.997\n",
      "Std dev of number of HTMGs (of means across indidivuals): 6.169\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.087\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.114\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.148\n",
      "\n",
      "120 minute window:\n",
      "Prior to EMA Response: No\n",
      "Mean number of HTMGs prior (aggregated data): 15.502\n",
      "Avg number of HTMGs (avg of means across indidivuals): 14.114\n",
      "Std dev of number of HTMGs (of means across indidivuals): 8.145\n",
      "Fraction of time no HTMGs in window (aggregated data): 0.068\n",
      "Avg fraction of time no HTMGs in window (of fractions across individuals): 0.103\n",
      "Std dev of fraction of time no HTMGs in window (of fractions across individuals): 0.149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculate the HTMG coverage for 5, 15, 30, and 60 minutes\n",
    "around the event time.\n",
    "'''\n",
    "\n",
    "summary_output(5)\n",
    "\n",
    "summary_output(15)\n",
    "\n",
    "summary_output(30)\n",
    "\n",
    "summary_output(60)\n",
    "\n",
    "summary_output(90)\n",
    "\n",
    "summary_output(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483.30132246017456\n",
      "31\n",
      "ANOVA p-value for current hour: 0.0\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Compute an anova decomposition using the poisson likelihood\n",
    "This will test if there are significant differences across\n",
    "individuals.\n",
    "'''\n",
    "\n",
    "llik_delta = 0; agg_llik_delta = 0\n",
    "output_delta = contingent_puff(delta)\n",
    "output_delta = np.asarray(output_delta)\n",
    "agg_sum_delta = np.asarray([np.sum(arr) for arr in output_delta])\n",
    "agg_mean_delta  = np.asarray([np.mean(arr) for arr in output_delta])\n",
    "agg_count_delta  = np.asarray([len(arr) for arr in output_delta])\n",
    "aggregate_frac_delta  = np.divide(np.sum(agg_sum_delta),np.sum(agg_count_delta))\n",
    "\n",
    "for i in range(0, agg_mean_delta.size):\n",
    "    user_mean = agg_mean_delta[i]\n",
    "    row = output_delta[i]\n",
    "    if user_mean > 0.0:\n",
    "        llik_delta += np.sum(np.subtract(np.multiply(row, np.log(user_mean)),user_mean))\n",
    "        agg_llik_delta += np.sum(np.subtract(np.multiply(row, np.log(aggregate_frac_delta)),aggregate_frac_delta))\n",
    "\n",
    "D_delta = -2*agg_llik_delta + 2*llik_delta\n",
    "print D_delta\n",
    "\n",
    "\n",
    "from scipy.stats import chi2\n",
    "n = np.sum(agg_count_delta)\n",
    "k = output_delta.shape[0]\n",
    "df = k-1\n",
    "print k\n",
    "\n",
    "print 'ANOVA p-value for current hour: %s' % (1-chi2.cdf(D_delta, df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
