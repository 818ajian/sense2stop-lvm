{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random EMA and HTMGs: Exploratory Data Analysis\n",
    "\n",
    "- This notebook is dedicated to understanding the number of HTMGs in the minutes prior to a Random EMA where the response was 'No' to smoking question\n",
    "- For multiple window-lengths (Delta), we compute the following descriptive statistics\n",
    "    + Mean number of HTMGs prior (aggregated data)\n",
    "    + Avg number of HTMGs (avg of means across indidivuals): \n",
    "    + Std dev of number of HTMGs (of means across indidivuals)\n",
    "    + Fraction of time no HTMGs in window (aggregated data)\n",
    "    + Avg fraction of time no HTMGs in window (of fractions across individuals)\n",
    "    + Std dev of fraction of time no HTMGs in window (of fractions across individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/final'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import packages and set directory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.getcwd()\n",
    "dir = \"/home/wdempsey/ExpanDrive/box/MD2K Northwestern/Processed Data/smoking-lvm-cleaned-data/final/\"\n",
    "os.chdir(dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary for converting random EMA responses\n",
    "## to numeric values (taking midpoint of interval)\n",
    "random_accptresponse = ['1 - 19 Minutes', '20 - 39 Minutes', '40 - 59 Minutes', \n",
    "                    '60 - 79 Minutes', '80 - 100 Minutes']\n",
    "random_dictionary = {'1 - 19 Minutes': 10, \n",
    "                     '20 - 39 Minutes': 30, \n",
    "                     '40 - 59 Minutes':50,\n",
    "                     '60 - 79 Minutes':70, \n",
    "                     '80 - 100 Minutes':90 } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in relevant data streams\n",
    "random_ema = pd.read_csv(dir + 'random-ema-final.csv')\n",
    "htmgs = pd.read_csv(dir + 'puff-probability-final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_puff(delta):\n",
    "    '''\n",
    "    Checks how many HTMGs within window of length _delta_ \n",
    "    prior to Random EMA with response 'No' to smoking status\n",
    "    '''\n",
    "    # print(\"Set delta to {} minutes\".format(delta))\n",
    "\n",
    "    htm_complete_yes = []\n",
    "    htm_complete_no = []\n",
    "    for id in set(random_ema['participant_id']) & set(htmgs['participant_id']):\n",
    "\n",
    "        puffmarker_id = np.where(htmgs['participant_id'] == id) \n",
    "        puffmarker_subset = htmgs.iloc[puffmarker_id[0]]\n",
    "        try:\n",
    "            puffmarker_dates_list = [datetime.datetime.strptime(date, '%m/%d/%y %H:%M') for date in puffmarker_subset['date']]\n",
    "        except:\n",
    "            puffmarker_dates_list = [datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in puffmarker_subset['date']]\n",
    "\n",
    "        random_id = np.where(random_ema['participant_id'] == id) \n",
    "        random_subset = random_ema.iloc[random_id[0]]\n",
    "\n",
    "        htm_id_list_yes = []\n",
    "        htm_id_list_no = []\n",
    "        for index, row in random_subset.iterrows():\n",
    "            try:\n",
    "                random_time = datetime.datetime.strptime(row['date'], '%m/%d/%y %H:%M')\n",
    "            except:\n",
    "                random_time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "            if row['when_smoke'] in random_accptresponse:\n",
    "                random_time = random_time - datetime.timedelta(minutes=random_dictionary[row['when_smoke']])\n",
    "            if row['when_smoke'] in random_accptresponse: \n",
    "                htm_count = 0\n",
    "                for index_puff in range(0,len(puffmarker_dates_list)):\n",
    "                    temp = abs((puffmarker_dates_list[index_puff] - random_time).total_seconds() / 60.0)\n",
    "                    if temp <= delta:\n",
    "                        htm_count += 1\n",
    "                htm_id_list_yes.append(htm_count)  \n",
    "            if row['smoke'] == 'No':\n",
    "                htm_count = 0\n",
    "                for index_puff in range(0,len(puffmarker_dates_list)):\n",
    "                    temp = abs((puffmarker_dates_list[index_puff] - random_time).total_seconds() / 60.0)\n",
    "                    if temp <= delta:\n",
    "                        htm_count += 1\n",
    "                htm_id_list_no.append(htm_count)  \n",
    "\n",
    "        htm_complete_yes.append(np.array(htm_id_list_yes, dtype = 'f'))\n",
    "        htm_complete_no.append(np.array(htm_id_list_no, dtype = 'f'))\n",
    "\n",
    "    return htm_complete_yes, htm_complete_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_output(delta):\n",
    "    '''\n",
    "    Constructs descriptive statistics using the output from \n",
    "    random_puff(delta) for specific choice of delta\n",
    "    '''\n",
    "        \n",
    "    output_delta_yes, output_delta_no = random_puff(delta)\n",
    "    agg_sum_delta_no = np.asarray([np.sum(arr) for arr in output_delta_no])\n",
    "    agg_mean_delta_no  = np.asarray([np.mean(arr) for arr in output_delta_no])\n",
    "    agg_mean_delta_no  = agg_mean_delta_no[~np.isnan(agg_mean_delta_no)]\n",
    "    agg_count_delta_no  = np.asarray([len(arr) for arr in output_delta_no])\n",
    "    agg_zero_delta_no  = np.asarray([np.count_nonzero(arr==0) for arr in output_delta_no], dtype='f')\n",
    "    ind_zero_delta_no = np.divide(agg_zero_delta_no, agg_count_delta_no)\n",
    "    ind_zero_delta_no = ind_zero_delta_no[~np.isnan(ind_zero_delta_no)]\n",
    "\n",
    "    aggregate_frac_delta_no = np.divide(np.sum(agg_sum_delta_no),np.sum(agg_count_delta_no))\n",
    "    aggregate_fraczero_delta_no = np.divide(np.sum(agg_zero_delta_no),np.sum(agg_count_delta_no))\n",
    "\n",
    "    agg_sum_delta_yes = np.asarray([np.sum(arr) for arr in output_delta_yes])\n",
    "    agg_mean_delta_yes  = np.asarray([np.mean(arr) for arr in output_delta_yes])\n",
    "    agg_mean_delta_yes = agg_mean_delta_yes[~np.isnan(agg_mean_delta_yes)]\n",
    "    agg_count_delta_yes  = np.asarray([len(arr) for arr in output_delta_yes])\n",
    "    agg_zero_delta_yes  = np.asarray([np.count_nonzero(arr==0) for arr in output_delta_yes], dtype='f')\n",
    "    ind_zero_delta_yes = np.divide(agg_zero_delta_yes, agg_count_delta_yes)\n",
    "    ind_zero_delta_yes = ind_zero_delta_yes[~np.isnan(ind_zero_delta_yes)]\n",
    "\n",
    "    aggregate_frac_delta_yes = np.divide(np.sum(agg_sum_delta_yes),np.sum(agg_count_delta_yes))\n",
    "    aggregate_fraczero_delta_yes = np.divide(np.sum(agg_zero_delta_yes),np.sum(agg_count_delta_yes))\n",
    "\n",
    "    print '% s minute window:' % (delta)\n",
    "    print 'Prior to EMA Response: No'\n",
    "    print 'Mean number of HTMGs prior (aggregated data): %s' % (np.round(aggregate_frac_delta_no,3))\n",
    "    print 'Avg number of HTMGs (avg of means across indidivuals): %s' % (np.round(np.mean(agg_mean_delta_no),3))\n",
    "    print 'Std dev of number of HTMGs (of means across indidivuals): %s' %  (np.round(np.std(agg_mean_delta_no),3))\n",
    "    print 'Fraction of time no HTMGs in window (aggregated data): %s' %  (np.round(np.sum(aggregate_fraczero_delta_no),3))\n",
    "    print 'Avg fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.mean(ind_zero_delta_no),3))\n",
    "    print 'Std dev of fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.std(ind_zero_delta_no),3))\n",
    "    print\n",
    "    '''\n",
    "    print '% s minute window:' % (delta)\n",
    "    print 'Prior to EMA Response: Yes'\n",
    "    print 'Mean number of HTMGs prior (aggregated data): %s' % (np.round(aggregate_frac_delta_yes,3))\n",
    "    print 'Avg number of HTMGs (avg of means across indidivuals): %s' % (np.round(np.mean(agg_mean_delta_yes),3))\n",
    "    print 'Std dev of number of HTMGs (of means across indidivuals): %s' %  (np.round(np.std(agg_mean_delta_yes),3))\n",
    "    print 'Fraction of time no HTMGs in window (aggregated data): %s' %  (np.round(np.sum(aggregate_fraczero_delta_yes),3))\n",
    "    print 'Avg fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.mean(ind_zero_delta_yes),3))\n",
    "    print 'Std dev of fraction of time no HTMGs in window (of fractions across individuals): %s' %  (np.round(np.std(ind_zero_delta_yes),3))\n",
    "    print\n",
    "    '''\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'contingent_complete' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bdb507b0089a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msummary_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msummary_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9c8c1c49c19e>\u001b[0m in \u001b[0;36msummary_output\u001b[0;34m(delta)\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput_delta_yes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_delta_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_puff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0magg_sum_delta_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_delta_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0magg_mean_delta_no\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_delta_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f164a51abe7b>\u001b[0m in \u001b[0;36mrandom_puff\u001b[0;34m(delta)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mhtm_complete_yes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mhtm_complete_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontingent_complete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'participant_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuffmarker_complete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'participant_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpuffmarker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpuffmarker_complete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'participant_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'contingent_complete' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculate the HTMG coverage for 5, 15, 30, and 60 minutes around the event time.\n",
    "'''\n",
    "\n",
    "summary_output(5)\n",
    "\n",
    "summary_output(15)\n",
    "\n",
    "summary_output(30)\n",
    "\n",
    "summary_output(60)\n",
    "\n",
    "summary_output(90)\n",
    "\n",
    "summary_output(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483.30132246017456\n",
      "31\n",
      "ANOVA p-value for current hour: 0.0\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Compute an anova decomposition using the poisson likelihood\n",
    "This will test if there are significant differences across\n",
    "individuals.\n",
    "'''\n",
    "\n",
    "llik_delta = 0; agg_llik_delta = 0\n",
    "output_delta = contingent_puff(delta)\n",
    "output_delta = np.asarray(output_delta)\n",
    "agg_sum_delta = np.asarray([np.sum(arr) for arr in output_delta])\n",
    "agg_mean_delta  = np.asarray([np.mean(arr) for arr in output_delta])\n",
    "agg_count_delta  = np.asarray([len(arr) for arr in output_delta])\n",
    "aggregate_frac_delta  = np.divide(np.sum(agg_sum_delta),np.sum(agg_count_delta))\n",
    "\n",
    "for i in range(0, agg_mean_delta.size):\n",
    "    user_mean = agg_mean_delta[i]\n",
    "    row = output_delta[i]\n",
    "    if user_mean > 0.0:\n",
    "        llik_delta += np.sum(np.subtract(np.multiply(row, np.log(user_mean)),user_mean))\n",
    "        agg_llik_delta += np.sum(np.subtract(np.multiply(row, np.log(aggregate_frac_delta)),aggregate_frac_delta))\n",
    "\n",
    "D_delta = -2*agg_llik_delta + 2*llik_delta\n",
    "print D_delta\n",
    "\n",
    "\n",
    "from scipy.stats import chi2\n",
    "n = np.sum(agg_count_delta)\n",
    "k = output_delta.shape[0]\n",
    "df = k-1\n",
    "print k\n",
    "\n",
    "print 'ANOVA p-value for current hour: %s' % (1-chi2.cdf(D_delta, df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
